{
  "name": "grunt-benchmark",
  "description": "Grunt task for benchmarking",
  "version": "0.1.3",
  "homepage": "https://github.com/shama/grunt-benchmark",
  "author": {
    "name": "Kyle Robinson Young",
    "email": "kyle@dontkry.com",
    "url": "http://dontkry.com"
  },
  "repository": {
    "type": "git",
    "url": "git://github.com/shama/grunt-benchmark.git"
  },
  "bugs": {
    "url": "https://github.com/shama/grunt-benchmark/issues"
  },
  "licenses": [
    {
      "type": "MIT",
      "url": "https://github.com/shama/grunt-benchmark/blob/master/LICENSE-MIT"
    }
  ],
  "main": "lib/grunt-benchmark.js",
  "engines": {
    "node": ">= 0.8.0"
  },
  "scripts": {
    "test": "grunt nodeunit"
  },
  "dependencies": {
    "ben": "*"
  },
  "keywords": [
    "gruntplugin",
    "benchmark"
  ],
  "devDependencies": {
    "grunt": "~0.4.0rc7",
    "grunt-contrib-jshint": "~0.1.1rc6",
    "grunt-contrib-nodeunit": "~0.1.2rc6",
    "grunt-contrib-watch": "~0.2.0rc7",
    "ncp": "~0.2.6"
  },
  "readme": "# grunt-benchmark\n\nGrunt task for benchmarking.\n\n*Warning: This is experimental and requires the devel version of Grunt.*\n\n## Getting Started\nInstall this grunt plugin next to your project's\n[Gruntfile][getting_started] with: `npm install grunt-benchmark`\n\nThen add this line to your project's Gruntfile:\n\n```javascript\ngrunt.loadNpmTasks('grunt-benchmark');\n```\n\n[grunt]: https://github.com/cowboy/grunt\n[getting_started]: https://github.com/cowboy/grunt/blob/master/docs/getting_started.md\n\n## Documentation\n\n### Basic Usage Example\nCreate a `benchmarks` folder and create a benchmark script within that folder,\nie `test-timeout.js`:\n\n```javascript\nmodule.exports = function(done) {\n  setTimeout(done, 100);\n};\n```\n\nThe setup your Gruntfile config to run the benchmarks within the `benchmarks`\nfolder 10 times:\n\n```javascript\ngrunt.initConfig({\n  benchmark: {\n    all: {\n      src: ['benchmarks/*.js'],\n      dest: 'benchmarks/results.csv',\n      options: {\n        times: 10\n      }\n    }\n  }\n});\n```\n\nThen run the task:\n\n```\n$ grunt benchmark\nRunning \"benchmark:all\" (benchmark) task\nBenchmarking \"0\" [benchmarks/test-timeout.js] x10...\n>> 101 ms per iteration\n```\n\nBenchmark name, date, times and per iteration will be logged in a csv format.\n\n### Benchmarking Tasks\nIncluded is a helper, `spawnTask`, for running Grunt tasks within your\nbenchmarks. This example will create a function to run the `watch` task:\n\n```javascript\n// benchmarks/watch.js\n// Create a spawnable watch task. Doesnt actually spawn until called.\nvar watchTask = require('grunt-benchmark').spawnTask('watch', {\n\n  // Text trigger to look for to know when to run the next step or exit\n  trigger: 'Waiting...',\n\n  // Base folder and Gruntfile\n  // You'll want to setup a fixture base folder and Gruntfile.js\n  // to ensure your Grunt'ing appropriately\n  base: 'path/to/a/gruntfile-base',\n  gruntfile: 'path/to/a/Gruntfile.js'\n\n  // Additional Grunt options can be specified here\n});\n\n// Our actual benchmark\nmodule.exports = function(done) {\n\n  // start the watch task\n  watchTask([function() {\n\n    // After trigger found, run this sync function\n    // this will trigger the watch task\n    grunt.file.write('path/to/file.js'), 'var test = false;');\n\n  }, function() {\n\n    // After the previous funciton has ran and another trigger hit...\n    // run this next sync function\n    grunt.file.delete('path/to/file.js');\n\n  }], function(result) {\n\n    // All done, do something more with the output result or finish up the benchmark\n    done();\n\n  });\n\n};\n```\n\n### `setUp` and `tearDown`\nSetup and teardown convenience functions are available in your benchmarks:\n\n```javascript\nmodule.exports = {\n  'setUp': function(done) {\n    // set up stuff here\n    done();\n  },\n  'tearDown': function(done) {\n    // tear down stuff here\n    done();\n  },\n  'run this benchmark': function(done) {\n    // do some processing here\n    done();\n  }\n};\n```\n\n**Remember! setUp and tearDown will be called before/after each benchmark test\nbut NOT each time a benchmark is ran.**\n\n## Contributing\nIn lieu of a formal styleguide, take care to maintain the existing coding style.\nLint and test your code using [grunt][grunt].\n\n## Release History\n* 0.1.3 Ability to log dest to a csv file. Support Grunt@0.4.0rc7.\n* 0.1.2 Update to work with Grunt@0.4.0rc3.\n* 0.1.1 Fix require path\n* 0.1.0 Initial release\n\n## License\nCopyright (c) 2012 Kyle Robinson Young\nLicensed under the MIT license.\n",
  "readmeFilename": "README.md",
  "_id": "grunt-benchmark@0.1.3",
  "_from": "grunt-benchmark@~0.1.1"
}
